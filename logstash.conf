input {
  file {
    path => ["/var/log/network.log"]
    #start_position => "beginning"
    type => "syslog"
    tags => [ "netsyslog" ]
  }

  file {
    path => ["/var/log/system.log"]
    #start_position => "beginning"
    type => "syslog"
    tags => [ "syssyslog" ]
  }
  redis {
    host => "172.16.206.245"
    data_type => "list"
    key => "logstash"
    codec => json
  }
  udp {
    host => "0.0.0.0"
    port => 2055
    codec => netflow { cache_ttl => 1
                       versions => [ 5, 9 ]
                     }
    type => "netflow"
    debug => true
  }

  file {
    path => ["/home/local/JTAX/curtisc/tax-returns/*"]
    start_position => "beginning"
    type => "tax_return"
    tags => [ "tax_return" ]
    codec => multiline {
      pattern => "^<\?xml .*\?>"
      negate => true
      what => "previous"
    }
    sincedb_path => "/var/log/logstash/.sincedb_tax_returns303"
  }
} #end input block

filter {
  if [type] == "syslog" {
    grok {
      #strips timestamp and host off of the front of the syslog message leaving the raw message generated by the syslog client and saves it as "raw_message"
      patterns_dir => "/opt/logstash/patterns"
      match => [ "message", "%{TIMESTAMP_ISO8601:@timestamp} %{HOST:syslog_host} %{GREEDYDATA:raw_message}" ]
    }
  }

  #classify network syslog logs as palo alto or ASA or other log
  if "netsyslog" in [tags] {
    grep {
      drop => false
      match => [ "raw_message", "%ASA-" ]
      add_tag => [ "asa_log", "firewall" ]
    }
    grep {
      drop => false
      match => [ "raw_message", ",TRAFFIC," ]
      add_tag => [ "palo_alto_log", "firewall" ]
    }
    grep {
      drop => false
      match => [ "raw_message", "User=.*Flags=.*cmd=" ]
      add_tag => [ "tacacs_accounting_log", "tacacs" ]
    }
    if "firewall" not in [tags] {
      mutate {
        add_tag => [ "generic_log" ]
      }
    }
  }

  if "palo_alto_log" in [tags] {
    #parse into csv and fix @timestamp to match the generate time of the log within the palo alto.
    csv {
      source => "raw_message"
      columns => [ "PaloAltoDomain","ReceiveTime","SerialNum","Type","Threat-ContentType","ConfigVersion","GenerateTime","SourceAddress","DestinationAddress","NATSourceIP","NATDestinationIP","Rule","SourceUser","DestinationUser","Application","VirtualSystem","SourceZone","DestinationZone","InboundInterface","OutboundInterface","LogAction","TimeLogged","SessionID","RepeatCount","SourcePort","DestinationPort","NATSourcePort","NATDestinationPort","Flags","IPProtocol","Action","Bytes","BytesSent","BytesReceived","Packets","StartTime","ElapsedTimeInSec","Category","Padding","seqno","actionflags","SourceCountry","DestinationCountry","cpadding","pkts_sent","pkts_received" ]
    }
    date {
      timezone => "America/New_York"
      match => [ "GenerateTime", "YYYY/MM/dd HH:mm:ss" ]
    }
    #convert fields to proper format
    mutate {
      convert => [ "Bytes", "integer" ]
      convert => [ "BytesReceived", "integer" ]
      convert => [ "BytesSent", "integer" ]
      convert => [ "ElapsedTimeInSec", "integer" ]
      convert => [ "geoip.area_code", "integer" ]
      convert => [ "geoip.dma_code", "integer" ]
      convert => [ "geoip.latitude", "float" ]
      convert => [ "geoip.longitude", "float" ]
      convert => [ "NATDestinationPort", "integer" ]
      convert => [ "NATSourcePort", "integer" ]
      convert => [ "Packets", "integer" ]
      convert => [ "pkts_received", "integer" ]
      convert => [ "pkts_sent", "integer" ]
      convert => [ "seqno", "integer" ]
      gsub => [ "Rule", " ", "_",
                "Application", "( |-)", "_" ]
      remove_field => [ "message", "raw_message" ]
    }
  } else if "asa_log" in [tags] {
    #parse ASA log
    grok {
      patterns_dir => "/opt/logstash/patterns"
      break_on_match => false
      match => [ "raw_message", "%{CISCOFACSEVMNEM} %{WORD:Action} %{IPPROTOCOL:IPProtocol} src %{WORD:SourceZone}:%{IP:SourceAddress}\/%{POSINT:SourcePort:int} dst %{WORD:DestinationZone}:%{IP:DestinationAddress}\/%{POSINT:DestinationPort:int} by access-group \"%{WORD:Rule}\"%{GREEDYDATA}",
                 "raw_message", "%{CISCOFACSEVMNEM} %{WORD:Action} %{IPPROTOCOL:IPProtocol} src %{WORD:SourceZone}:%{IP:SourceAddress} dst %{WORD:DestinationZone}:%{IP:DestinationAddress} %{DATA:icmp_type_code} by access-group \"%{WORD:Rule}\"%{GREEDYDATA}",
                 "raw_message", "%{CISCOFACSEVMNEM} %{GREEDYDATA:description}" ]
    }
    mutate {
      remove_field => [ "message", "raw_message" ]
      add_field => [ "Application", "asa_unknown" ]
      lowercase => [ "Action" ]
    }
  } else if "tacacs_accounting_log" in [tags] {
    grok {
      patterns_dir => "/opt/logstash/patterns"
      break_on_match => false
      match => [ "raw_message", "%{TIMESTAMP_ISO8601} %{IPORHOST:tacacs_server} %{DATESTAMP} NAS_IP=%{IPORHOST:source_device} %{DATA} User=%{WORD:user} %{DATA} cmd=%{GREEDYDATA:command}" ]
    }
    mutate {
      remove_field => [ "message", "raw_message" ]
    }
  } else if "tax_return" in [tags] {
      xml {
        source => "message"
        target => "return"
      }

  } else {
    #apply actions to logs that don't match any particular type of log
  }

  #Geolocate logs that have SourceAddress and if that SourceAddress is a non-RFC1918 address
  if [SourceAddress] and [SourceAddress] !~ "(^127\.0\.0\.1)|(^10\.)|(^172\.1[6-9]\.)|(^172\.2[0-9]\.)|(^172\.3[0-1]\.)|(^192\.168\.)" {
      geoip {
           database => "/opt/logstash/GeoLiteCity.dat"
           source => "SourceAddress"
      }
      mutate {
        # 'coords' will be kept, 'tmplat' is temporary.
        # Both of these new fields are strings.
        add_field => [ "coords", "%{[geoip][longitude]}",
                       "tmplat", "%{[geoip][latitude]}" ]
      }
      mutate {
        # Merge 'tmplat' into 'coords'
        merge => [ "coords", "tmplat" ]
      }
      mutate {
        # Convert our new array of strings back to float
        convert => [ "coords", "float" ]
        # Delete our temporary latitude field
        remove_tag => [ "tmplat" ]
      }
    }

  #parse windows event logs shipped from windows servers
  if [type] == "Win32-EventLog" {
    grok {
      patterns_dir => "/opt/logstash/patterns"
      break_on_match => false
      match => [ "message", "%{DATA}(Logon Account:|Account Name:)%{SPACE}%{USERNAME:username}%{GREEDYDATA}",
                 "message", "%{DATA}%{GREEDYDATA}" ]
    }
    grok {
      patterns_dir => "/opt/logstash/patterns"
      break_on_match => false
      match => [ "message", "%{DATA}(Client Address:|Source Network Address:|Source Workstation:)%{SPACE}(::ffff:)?%{IPORHOST:client_address}%{GREEDYDATA}",
                 "message", "%{DATA}%{GREEDYDATA}" ]
    }
  }

} #end filter block

output {
  #stdout { codec => rubydebug }
  #stdout { debug => true }
  elasticsearch {
    embedded => true
  }
} #end output block

